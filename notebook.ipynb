{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Task-1---Correcting-categories\" data-toc-modified-id=\"Task-1---Correcting-categories-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Task 1 - Correcting categories</a></span></li><li><span><a href=\"#Task-2---updating-/-correcting-brand-names\" data-toc-modified-id=\"Task-2---updating-/-correcting-brand-names-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Task 2 - updating / correcting brand names</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no \"ground truth\" in the data (as there are mistakes in it), I have used an unsupervised approach that attempts to learn the empirical distributions of categories and hopefully corrects any mistakes accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Correcting categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import operator\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"file7_andrea.xlsx\")\n",
    "\n",
    "cat_mix = pd.read_excel(\"Latest category mix 03-05-2019.xlsx\")\n",
    "\n",
    "unique_cats = list(df['cat0fk'].unique())\n",
    "\n",
    "mean_prices = df.groupby(\"cat0fk\")[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the empirical probability for each unigram and bigram per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:29<00:00, 12.79s/it]\n"
     ]
    }
   ],
   "source": [
    "count_name_tokens = {}\n",
    "\n",
    "# For each category...\n",
    "for cat in tqdm(unique_cats):\n",
    "    \n",
    "    count_cat = {}\n",
    "    \n",
    "    # Get the list of unigrams...\n",
    "    unigrams = df[df['cat0fk'] == cat]['clean_name'].to_list()\n",
    "    \n",
    "    unigrams = [item for sublist in unigrams for item in sublist.split() if item not in stop_words]\n",
    "    \n",
    "    total_unigrams = len(unigrams)\n",
    "    \n",
    "    # Then count the occurence of each unigram. Divide by total to create probability\n",
    "    # This is the a-priori (default) probaility for each token in each class\n",
    "    for unigram in unigrams:\n",
    "        count_cat[unigram] = unigrams.count(unigram)/total_unigrams\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Do the same for bigrams\n",
    "    bigrams = [(unigrams[i], unigrams[i+1]) for i in range(len(unigrams)-1)]\n",
    "    \n",
    "    total_bigrams = len(bigrams)\n",
    "    \n",
    "    for bigram in bigrams:\n",
    "        count_cat[bigram] = bigrams.count(bigram)/total_bigrams\n",
    "    \n",
    "    count_name_tokens[cat] = count_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the updating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1\n",
    "\n",
    "def reassign(product):\n",
    "    \n",
    "    text = product['clean_name']\n",
    "    price = product['price']\n",
    "    \n",
    "    original_category = product['cat0fk']\n",
    "        \n",
    "    likelihood = dict.fromkeys(unique_cats, 0)\n",
    "    \n",
    "    min_price_diff = sys.maxsize\n",
    "    \n",
    "    unigrams = text.split()\n",
    "    \n",
    "    bigrams = [(unigrams[i], unigrams[i+1]) for i in range(len(unigrams) - 1)]\n",
    "    \n",
    "    \n",
    "    # Calculate likelihood for each unigram\n",
    "    for unigram in unigrams:\n",
    "        cat_unigram_appearance = 0\n",
    "        for cat, word_scores in count_name_tokens.items():\n",
    "            if unigram in word_scores:\n",
    "                cat_unigram_appearance += 1\n",
    "                \n",
    "        try:\n",
    "            cat_unigram_weight = 1 / cat_unigram_appearance\n",
    "        except:\n",
    "            cat_unigram_weight = 1\n",
    "            \n",
    "        for cat, word_scores in count_name_tokens.items():\n",
    "            if unigram in word_scores:\n",
    "                likelihood[cat] += cat_unigram_weight * word_scores[unigram]\n",
    "                \n",
    "                \n",
    "    # Calculate likelihood for each bigram\n",
    "    for bigram in bigrams:\n",
    "        # cat_bigram_weight = 1\n",
    "        cat_bigram_appearance = 0\n",
    "       \n",
    "        for cat, word_scores in count_name_tokens.items():\n",
    "            \n",
    "            if bigram in word_scores:\n",
    "                \n",
    "                cat_bigram_appearance += 1\n",
    "        try:\n",
    "            cat_bigram_weight = 1 / cat_bigram_appearance\n",
    "        except:\n",
    "            cat_bigram_weight = 1\n",
    "        \n",
    "        for cat, word_scores in count_name_tokens.items():\n",
    "            \n",
    "            if bigram in word_scores:\n",
    "                \n",
    "                # Bigram likelihood get weighted by an additional 10\n",
    "                likelihood[cat] += 10 * cat_bigram_weight * word_scores[bigram]\n",
    "               \n",
    "            \n",
    "    likelihood = {k: v for k, v in sorted(likelihood.items(), key = lambda item: item[1],\n",
    "                                          reverse = True)}\n",
    "    \n",
    "    original_likelihood = likelihood[original_category]\n",
    "        \n",
    "    most_prob_tag = max(likelihood.items(), key = operator.itemgetter(1))[0]\n",
    "    \n",
    "    most_prob_likelihood = likelihood[most_prob_tag]\n",
    "    \n",
    "    \n",
    "    # Keep the original tag if the difference in likelihood\n",
    "    # between new and original categories is relatively low\n",
    "    if (most_prob_likelihood - original_likelihood)/original_likelihood < threshold:\n",
    "        most_prob_tag = original_category\n",
    "    \n",
    "    return most_prob_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating categories for each row based on the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat0fk_corrected = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    cat0fk_corrected.append(reassign(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat0fk_corrected'] = cat0fk_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>price</th>\n",
       "      <th>mapped_brands</th>\n",
       "      <th>cat0fk</th>\n",
       "      <th>cat0fk_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Royal Canin Persian Adult 30 Cat Food, 4 kg</td>\n",
       "      <td>royal canin persian adult 30 cat food 4 kg</td>\n",
       "      <td>439.0</td>\n",
       "      <td>royal canin</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL CARE Reusable Latex Rubber Household Han...</td>\n",
       "      <td>royal care reusable latex rubber household han...</td>\n",
       "      <td>345.0</td>\n",
       "      <td>royal</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Royal Carpet High Density Artificial Grass Car...</td>\n",
       "      <td>royal carpet high density artificial grass car...</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>royal</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Royal Comfort Zone Cotton Mattress (Orange, 72...</td>\n",
       "      <td>royal comfort zone cotton mattress orange 72x3...</td>\n",
       "      <td>649.0</td>\n",
       "      <td>royal comfort</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Royal Crown Austrian Crystal Silver Designer R...</td>\n",
       "      <td>royal crown austrian crystal silver designer r...</td>\n",
       "      <td>215.0</td>\n",
       "      <td>royal crown</td>\n",
       "      <td>LifeStyle</td>\n",
       "      <td>LifeStyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  \\\n",
       "0        Royal Canin Persian Adult 30 Cat Food, 4 kg   \n",
       "1  ROYAL CARE Reusable Latex Rubber Household Han...   \n",
       "2  Royal Carpet High Density Artificial Grass Car...   \n",
       "3  Royal Comfort Zone Cotton Mattress (Orange, 72...   \n",
       "4  Royal Crown Austrian Crystal Silver Designer R...   \n",
       "\n",
       "                                          clean_name   price  mapped_brands  \\\n",
       "0         royal canin persian adult 30 cat food 4 kg   439.0    royal canin   \n",
       "1  royal care reusable latex rubber household han...   345.0          royal   \n",
       "2  royal carpet high density artificial grass car...  1170.0          royal   \n",
       "3  royal comfort zone cotton mattress orange 72x3...   649.0  royal comfort   \n",
       "4  royal crown austrian crystal silver designer r...   215.0    royal crown   \n",
       "\n",
       "      cat0fk cat0fk_corrected  \n",
       "0       Home             Home  \n",
       "1       Home             Home  \n",
       "2       Home             Home  \n",
       "3       Home             Home  \n",
       "4  LifeStyle        LifeStyle  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried getting the right categories on Flipkart's API but I did not have the credentials to access it. An external reference will help a great deal in improving this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - updating / correcting brand names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use SpaCy's pretrained model for named entity extraction and POS tagging.\n",
    "\n",
    "See - https://github.com/explosion/spacy-models/releases//tag/en_core_web_lg-2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# All possible brand names\n",
    "possible_brands = df['mapped_brands'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here - \n",
    "NER = Entities extracted from SpaCy\n",
    "\n",
    "When updating each brand name, I have thought of four possible cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_brands(product):\n",
    "    \n",
    "    # Extracting fields from row\n",
    "    product_name = product['clean_name']\n",
    "    brand_name = product['mapped_brands']\n",
    "    \n",
    "    # Feeding the name into SpaCy's model\n",
    "    doc = nlp(product['clean_name'])\n",
    "\n",
    "    \n",
    "    product_name_tokens = product_name.split()\n",
    "    \n",
    "    try:\n",
    "        brand_name_tokens = brand_name.split()\n",
    "        len_brand = len(brand_name_tokens)\n",
    "    except:\n",
    "        len_brand = 1\n",
    "    \n",
    "    # This will contain the corrected brand name\n",
    "    mapped_corrected = []\n",
    "    \n",
    "    # If no entities are found in the product name, \n",
    "    # set the first two tokens in the product name as the brand name (my assumption)\n",
    "    if not doc.ents:\n",
    "        string = \"\"\n",
    "        for substr in product_name_tokens[:2]:\n",
    "            string += (substr + \" \")\n",
    "        mapped_corrected = string\n",
    "    \n",
    "    # Loop through every detected entity...\n",
    "    for entity in doc.ents:\n",
    "        \n",
    "        ent_start = entity.start\n",
    "        ent_end = entity.end\n",
    "        \n",
    "        entity_tokens = [token for token in doc[ent_start: ent_end]]\n",
    "    \n",
    "    \n",
    "        if type(brand_name) == str:\n",
    "            \n",
    "            # Case 1 - tokens exist in both NER and mapped_brands\n",
    "            \n",
    "            # Checking for overlap in brand_name_tokens and entity_tokens\n",
    "            if bool(set(brand_name_tokens) & set(entity_tokens)):\n",
    "                mapped_corrected = brand_name\n",
    "                break\n",
    "                \n",
    "                \n",
    "                \n",
    "            # Case 2 - tokens exist in mapped_brands but not NER\n",
    "            else:\n",
    "                set_mb = set(brand_name_tokens)\n",
    "                set_pn = set(product_name_tokens)\n",
    "                \n",
    "                pn_mb_overlap = set_mb & set_pn\n",
    "                \n",
    "                pn_mb_overlap = [x for x in product_name_tokens if x in pn_mb_overlap]                \n",
    "                \n",
    "                if pn_mb_overlap:\n",
    "                    string = \"\"\n",
    "                    for substr in pn_mb_overlap:\n",
    "                        string += (substr + \" \")\n",
    "                    mapped_corrected = string\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "            \n",
    "        # Case 3 - tokens exist in NER but not mapped_brands\n",
    "        elif math.isnan(brand_name):\n",
    "            if bool(set(product_name_tokens) & set(entity_tokens)):\n",
    "                mapped_corrected = entity.text\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Case 4 - tokens do not exist in both mapped_brands and NER\n",
    "            else:\n",
    "                string = \"\"\n",
    "                for substr in product_name_tokens[:len_brand]:\n",
    "                    string += (substr + \" \")\n",
    "                mapped_corrected = string\n",
    "                break\n",
    "    \n",
    "    # If no criteria was fulfilled in the previous steps, simply return the brand name as is\n",
    "    if not mapped_corrected:\n",
    "        mapped_corrected = brand_name\n",
    "                \n",
    "    return mapped_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6056it [02:13, 45.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Execute the above function for all rows\n",
    "\n",
    "mapped_brands_corrected = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    mapped_brands_corrected.append(map_brands(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mapped_brands_corrected'] = mapped_brands_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>price</th>\n",
       "      <th>mapped_brands</th>\n",
       "      <th>cat0fk</th>\n",
       "      <th>cat0fk_corrected</th>\n",
       "      <th>mapped_brands_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>The Great Ages of World Architecture (With Int...</td>\n",
       "      <td>the great ages of world architecture with intr...</td>\n",
       "      <td>365.0</td>\n",
       "      <td>the</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>the great gatsby</td>\n",
       "      <td>79.0</td>\n",
       "      <td>the</td>\n",
       "      <td>BGM</td>\n",
       "      <td>BGM</td>\n",
       "      <td>the great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>The Greatness Guide 2</td>\n",
       "      <td>the greatness guide 2</td>\n",
       "      <td>244.0</td>\n",
       "      <td>the</td>\n",
       "      <td>BGM</td>\n",
       "      <td>BGM</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>The Gruffalo's Child Magnet Book</td>\n",
       "      <td>the gruffalo s child magnet book</td>\n",
       "      <td>520.0</td>\n",
       "      <td>the</td>\n",
       "      <td>BGM</td>\n",
       "      <td>BGM</td>\n",
       "      <td>the gruffalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>The Heartfulness Way (Kannada)</td>\n",
       "      <td>the heartfulness way kannada</td>\n",
       "      <td>180.0</td>\n",
       "      <td>the</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           product_name  \\\n",
       "6051  The Great Ages of World Architecture (With Int...   \n",
       "6052                                   The Great Gatsby   \n",
       "6053                              The Greatness Guide 2   \n",
       "6054                   The Gruffalo's Child Magnet Book   \n",
       "6055                     The Heartfulness Way (Kannada)   \n",
       "\n",
       "                                             clean_name  price mapped_brands  \\\n",
       "6051  the great ages of world architecture with intr...  365.0           the   \n",
       "6052                                   the great gatsby   79.0           the   \n",
       "6053                              the greatness guide 2  244.0           the   \n",
       "6054                   the gruffalo s child magnet book  520.0           the   \n",
       "6055                       the heartfulness way kannada  180.0           the   \n",
       "\n",
       "           cat0fk cat0fk_corrected mapped_brands_corrected  \n",
       "6051         Home             Home                    the   \n",
       "6052          BGM              BGM              the great   \n",
       "6053          BGM              BGM                    the   \n",
       "6054          BGM              BGM           the gruffalo   \n",
       "6055  Electronics      Electronics                    the   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is for products without a brand name. \"The\" seems to be captured as the brand name, even when it isn't correct. This can be solved to an extent by writing a rule to omit tokens with POS tags == 'DET' in SpaCy. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
